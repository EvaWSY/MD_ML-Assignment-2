---
title: "Assignment 2"
author: "James Wu, Hongye Wu, Eva Wang(sw2860)"
date: "October 4, 2018"
output: md_document
---
```{r,warning=F,message=FALSE,echo=F}
require(tidyverse)
require(stargazer)
require(MASS)
```


# Logistic regression applied to voting

## A: Explore the exit poll data
```{r,message=FALSE}
#Read in data
poll_data <- read_tsv("./Data/poll_data.tsv")
names(poll_data)
summary(poll_data)
```

## B: Build a logistic regression model
```{r}
#Transform vote_2008 into binary and race into a factor variable
poll_data <- poll_data %>% 
  transmute(
    state,
    sex,
    race,
    age,
    education,
    party,
    ideology,
    vote_2008 = ifelse(vote_2008 == "barack obama", 1, 0),
    state_contestedness
  )

#Run logistic model with all variables
poll_model <- glm(formula = vote_2008 ~ 1 + .,family = "binomial",data = poll_data)
```

#### i. List the coefficients for each age group and gender; if your model does not fit all these coefficients, explain why not.
```{r}
#coefficients of age groups and gender
poll_model$coefficients[which(names(poll_model$coefficients) %in% c("age30-44","age45-64","age65+","sexmale"))]
```
Some levels for an variable is dropped by the model to avoid multicollinearity, because they serve as the reference points for the other levels for the same variable. The coefficients listed in the model are relative to the reference group. Being a male decreases the log odds of voting for Obama by 0.0232 when compared to being a female. The older the age bracket a person is in, decreases the log odds of voting for Obama by the above amounts when compared to the 18-29 age bracket.

#### ii. Provide a summary of the model. What is your interpretation of these values?
```{r}
summary(poll_model)
```

The coefficients describe the increase or decrease in the log odds of voting for Obama based on the state, race, age group, ideology, education level, and political party the person is in. However, only a handful of independent variables are statistically significant in this model: 
- raceblack, racehispanic, and raceother. A non-white person is more likely to vote for Obama. Being black, in particular, is associated with an increase of log odds by 3.07 to support Obama, which is much higher than the increase of log odds associated with other non-white races and ethnicities.
- `age30-44`, `age45-64`, and `age65+`. These age groups are associated with a decrease log odds to vote for Obama. 
- `educationhigh school graduate`, and `educationsome college`. These education groups are associated with a decrease log odds to vote for Obama.
- If a person is not a democrat, they are more likely to vote for mcCain.
- A liberal or moderate person is more likely to vote for Obama. 
The reason for the NAs for the state_contestedness variables, is due to perfect collinearity with the state info.

#### iii.  Convert the probabilistic predictions for each individual into binary predictions, based on the candidate they are most likely to vote for. Compute accuracy, precision, and recall for your predictions.
```{r}
#Convert to probabilistic predictions
poll_model_pred <- predict(poll_model, type = 'response')
#Change this to binary predictions based on if the predicted probability is >0.5 = "obama"
poll_data <- mutate(poll_data, predict1 = ifelse(poll_model_pred > 0.5,"barack obama","john mcCain"))

# Calculate accuracy, assuming Obama is the positive result (accuracy = (true psoitive +true negative)/total observations)
total_obs <- 10000L

accurate_pred <- poll_data %>% 
  filter(
    (vote_2008 == "1" & predict1 == "barack obama") | ((vote_2008 == "0" & predict1 == "john mcCain"))
  ) %>% 
  nrow()

accurate_pred/total_obs*100

# Recall (recall = true positive/total actual postive)

true_pos <- poll_data %>% 
  filter(
   vote_2008 == "1" & predict1 == "barack obama"
  ) %>% 
  nrow()

positives <- poll_data %>% filter(vote_2008 == "1") %>% nrow()

true_pos/positives*100

# Precision (precision = true positive/total predicted positive)

pred_positives <- poll_data %>% filter(predict1 == "barack obama") %>% nrow()

true_pos/pred_positives*100
```
The overall accuracy rate for the model is 85.77%.
The recall rate is 89.5%.
The precision is 86.1%.

#### iv.  Repeat step iii), but now convert each individual's prediction to a binary prediction for Obama only if the individual's probability of voting for Obama is at least 70%. What differences do you see in accuracy, precision, and recall compared to step iii)?
```{r}
#Change probability to binary predictions based on if the predicted probability is >=0.7 = "obama"
poll_data <- mutate(poll_data, predict2 = ifelse(poll_model_pred >= 0.7,"barack obama","john mcCain"))
# Calculate accuracy, assuming Obama is the positive result
total_obs <- 10000L

accurate_pred2 <- poll_data %>% 
  filter(
    (vote_2008 == "1" & predict2 == "barack obama") | ((vote_2008 == "0" & predict2 == "john mcCain"))
  ) %>% 
  nrow()

accurate_pred2/total_obs*100

# Recall

true_pos2 <- poll_data %>% filter(vote_2008 == "1" & predict2 == "barack obama") %>% nrow()

true_pos2/positives*100

# Precision

pred_positives2 <- poll_data %>% filter(predict2 == "barack obama") %>% nrow()

true_pos2/pred_positives2*100
```
```{r}
#Compare the results of iii and iv
probability = c("at least 50%","at leasts 70%")
accuracy = c(accurate_pred/total_obs*100, accurate_pred2/total_obs*100)
recall = c(true_pos/positives*100,true_pos2/positives*100)
precision = c(true_pos/pred_positives*100,true_pos2/pred_positives2*100)
data.frame(probability,accuracy,recall,precision)
```
 - The overall accuracy is 82.93%. A little lower than in step iii (85.77%).
 - Recall here is 77.1% and precision is 91.7%. Even though recall is significantly lower than in step iii, precision is improved. It means when increasing the prediction probabilities, the ability of making predicted positives that are true postives are increased. So the model is less likely to classify a person as Obama's supporter when they are actually not than the previous configuration in step iii. 


## C: Download and explore the revised exit poll data
```{r,message=FALSE}
#Read in data
poll_data_full <- read_tsv("./Data/poll_data_full.tsv")
```


#### i. Using this revised exit poll data, build a binary logistic regression model to predict whether an individual voted for a major-party candidate in the 2008 elections. Make a histogram of the resulting predicted probabilities using ggplot2.
```{r}
#create a new variable collapsing obama and mcCain votes to 1 and others as 0
poll_data_full = mutate(poll_data_full,major_or_not = ifelse(vote_2008 == "other",0,1)) 
#Logistic Regression
poll_full_model <- glm(formula = major_or_not ~ 1 + .,family = "binomial",data = poll_data_full %>% dplyr::select(-vote_2008))

#Convert to probabilistic predictions
poll_full_model_pred <- predict(poll_full_model, type = 'response')
poll_data_full <- mutate(poll_data_full,predictprob = poll_full_model_pred)

#Histogram with predicted probabilities
ggplot(poll_data_full,aes(x=predictprob)) +
  geom_histogram(bins = 100) +
  labs(x = "Probability of Voting for Major Candidate (2008)")
```

#### ii. Filter the revised exit poll data to only individuals who actually voted for major party candidates. On this subset, build a binary logistic regression model to predict whether an individual voted for Obama. This gives an estimate of Pr(voted Obama | voted major party candidate).

```{r}
#filter the poll data to only individuals who actually voted for major party candidates
poll_full_major_data <- filter(poll_data_full,major_or_not == 1)

poll_full_major_data$vote_2008 <- factor(poll_full_major_data$vote_2008,levels = c("john mcCain","barack obama"))

#Logistic regression
poll_full_major_model <- glm(formula = vote_2008 ~ 1 + .,family = "binomial",data = poll_full_major_data %>% dplyr::select(-major_or_not))
```



#### iii. Using the model from step ii), generate estimates of Pr(voted Obama | voted major party candidate) for every individual in the revised exit poll data, and make a histogram of the resulting predicted probabilities using ggplot2.
```{r}
#Convert to probabilistic predictions
poll_full_major_model_pred <- predict(poll_full_major_model, type = 'response')
poll_full_major_data <- mutate(poll_full_major_data,predictprob = poll_full_major_model_pred)
#Histogram of the predicted conditional probability
ggplot(poll_full_major_data,aes(x=predictprob)) +
  geom_histogram(bins = 100) +
  labs(x = "Probability of Voting for Obama | Voted Major Candidate (2008)")
```


#### iv. Use the models from steps i) and ii) to compute, for each individual, the probability that the individual votes for the three candidates. Generate categorical predictions for each individual based on these probabilities, and report the accuracy of your classifier.
```{r}
# In i) we predicted whether a person was going to vote other. In ii) we predicted whether those who voted major candidates voted either obama or mcCain. We would just need to combine these two predictions into one via a two-step categorizing process.

# The problem is the prediction of whether a person voted for a major candidate or not did not seem accurate, as the predicted probablities were mostly 90%+. I'll try building grid search function to find the optimal cutoff for accuracy.
OptAccuracy <- function(dataframe, PredictVarName,ClassifierVarName){
  PredictedClassifier <- dataframe[,PredictVarName]
  Classifier <- dataframe[,ClassifierVarName]
  nPoints <- nrow(PredictedClassifier)
  p_grid <- seq(from = min(PredictedClassifier), to = max(PredictedClassifier),length.out = nPoints)
  AccuracyVector <- rep(NA,nPoints)
  
  for(i in 1:length(p_grid)){
    AccuracyVector[i] <- sum(ifelse(PredictedClassifier > p_grid[i],1,0) == Classifier)/nPoints
  }
  
  p_grid[which.max(AccuracyVector)]
  #plot(AccuracyVector~p_grid)
}

OptAccuracy(poll_data_full,"predictprob","major_or_not")
```
We see the optimal cutoff is the minimum prediction probability. In other words, to improve our accuracy, we should essentially predict everybody to have voted for a major candidate.

```{r}
poll_full_major_data <- mutate(poll_full_major_data, vote_2008 = ifelse(vote_2008 == "barack obama", 1, 0))
OptAccuracy(poll_full_major_data,"predictprob","vote_2008")
```
Within the people who voted a major candidate, the optimal cutoff point for the highest accuracy is around 0.5.

```{r}
# Create categorical predictions for the three candidates 
poll_data_full <- mutate(poll_data_full,pred_candidates = NA)
poll_data_full[,"pred_candidates"] <- ifelse(poll_full_model_pred < 0.7380653,"Other",NA)
poll_data_full[which(poll_data_full$major_or_not == 1),"pred_candidates"] <- ifelse(poll_full_major_model_pred >= 0.5,"barack obama","john mcCain")

#Accuracy
sum(poll_data_full$pred_candidates == poll_data_full$vote_2008,na.rm=T)/nrow(poll_data_full)
```
 - The accuracy of our classifier is 84.14%


```{r}

# Create categorical predictions for the three candidates 
poll_data_full <- poll_data_full %>% 
  mutate(
   pred_candidates = case_when(
     poll_full_model_pred < 0.5 ~"Other",
     poll_full_major_model_pred > 0.5 ~ "barack obama", 
     poll_full_major_model_pred < 0.5 ~ "john mcCain") #doesn't run because poll_full_major_model_pred does not apply to all individuals

# Accuracy   
   
```
